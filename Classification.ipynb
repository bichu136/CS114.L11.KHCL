{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bichu136/CS114.L11.KHCL/blob/master/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12DceB91V80e"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo0sNLuuWL-h"
      },
      "source": [
        "mong muốn của bài toán phân loại là bài toán mà đầu ra của chúng ta là 0 hoặc 1, với:\n",
        "- 0 biểu thị cho sự vắn mặt, ko hiển thị của tính chất mà chúng ta đang xét ở input đầu vào \n",
        "- 1 biểu thị cho sự hiện diện của 1 tính chất mà chúng ta đang xét ở input đầu vào.\n",
        "\n",
        "=>Từ đó ta có thể nói được rằng input của bài toán này có thuộc lớp phân loại đang xét hay không."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrnxhCN8WBI9"
      },
      "source": [
        "## Logistic regression\n",
        "\n",
        "1. ### sigmoid function(logistic function)\n",
        "Ứng với mỗi $x \\in R$  là đầu vào của hàm thì hàm này sẽ có dạng.<br>\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-6b67bea3311c3429bfb34b6b1737fe0c)<br>\n",
        "<br>\n",
        "Có vẻ gần giống với mong muốn của bài toán.<br>\n",
        "\n",
        "#### Cho rằng:\n",
        "- y=1 nếu như $\\sigma(x)\\geq 0.5$ => $x\\geq0$\n",
        "- y=0 nếu như $\\sigma(x)< 0.5$ => $x<0$\n",
        "2. ### Decision boundary \n",
        "Như đã nói ở trên, việc phân lớp chỉ còn lại là tìm ra đầu vào cho sigmoid function thông qua dữ liệu đầu vào thật sự của bài toán phân lớp $X=\\{x_1,x_2,x_3,...,x_n\\}$. với n là số chiều của dữ liệu. <br>\n",
        "=> ta có thể kiếm 1 đường thẳng sao cho $f_\\theta(X)=\\theta^T X$ \n",
        "thì đường thẳng đó có thể chia dữ liệu ra làm 2 phần.<br><br>\n",
        "Hàm tổng quát cho bài toán $\\sigma(f_\\theta(X)) = h_\\theta(X)$ \n",
        "![alt text](https://www.shuhanyu.com/2018/07/08/MLofLogisticRegressionWithDecisionBoundary/DecisionBoundary.png)<br>\n",
        "3. ### Cost function\n",
        "  với bộ dữ liệu cho trước $D={(X_1,y_1),....(X_k,y_k)}$ với k là số lượng dòng dữ liệu. <br>\n",
        "  $$cost(X,y)=\n",
        "  \\begin{Bmatrix}\n",
        "  -log(h_\\theta(X))&với\\ y=1\\\\\n",
        "  -log(1-h_\\theta(X))&với\\ y=0\n",
        "  \\end{Bmatrix}\n",
        "  $$\n",
        "  và để dễ dàng tính toán, ta có thể viết.\n",
        "  $$\n",
        "  cost(X,y)=-(ylog(h_\\theta(X)) +(1-y)log(1-h_\\theta(X)))\n",
        "  $$\n",
        "4. ### Gradient Descent\n",
        "giống như mục tiêu của Linear Regression, mục tiêu mà chúng ta nhắm đến là means của Cost function trên tập dữ liệu là nhỏ nhất.\n",
        "$$\n",
        "minJ(\\theta) = \\frac{1}{k}\\sum_{i=1}^{k}cost(X_i,y_i)=\\frac{1}{k}\\sum_{i=1}^{k}(ylog(h_\\theta(X)) +(1-y)log(1-h_\\theta(X)))\n",
        "$$\n",
        "áp dụng thuật toán linear regression\n",
        "repeat{<br>\n",
        "$$ \\theta_j:=\\theta $$\n",
        "<br>\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgWsG6YDVrhp"
      },
      "source": [
        "## Code mẫu của scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqBKJmU4vMl4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "sys.setrecursionlimit(99999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a73maPK_z7bz"
      },
      "source": [
        "!cat fetal_health.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtXqOnzavTb2"
      },
      "source": [
        "# import data\n",
        "data = pd.read_csv('fetal_health.csv')\n",
        "data = np.array(data)\n",
        "X = data[:, :-1]\n",
        "Y = data[:, -1:]\n",
        "\n",
        "split = len(X)//2\n",
        "X_train = X[:-split]\n",
        "Y_train = Y[:-split]\n",
        "\n",
        "X_test = X[-split:]\n",
        "Y_test = Y[-split:]\n",
        "\n",
        "print(len(X_test))\n",
        "print(len(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXyMfc1J6Dmd",
        "outputId": "472b975f-feea-4103-f467-bfecf6c89b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(X_train))\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(1063, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSnvZ5DV-rXY",
        "outputId": "3ce2cc0e-2b05-4416-de78-47ec028cd137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.20e+02 0.00e+00 0.00e+00 ... 1.21e+02 7.30e+01 1.00e+00]\n",
            " [1.32e+02 6.00e-03 0.00e+00 ... 1.40e+02 1.20e+01 0.00e+00]\n",
            " [1.33e+02 3.00e-03 0.00e+00 ... 1.38e+02 1.30e+01 0.00e+00]\n",
            " ...\n",
            " [1.40e+02 1.00e-03 0.00e+00 ... 1.52e+02 4.00e+00 1.00e+00]\n",
            " [1.40e+02 1.00e-03 0.00e+00 ... 1.51e+02 4.00e+00 1.00e+00]\n",
            " [1.42e+02 2.00e-03 2.00e-03 ... 1.45e+02 1.00e+00 0.00e+00]]\n",
            "[[2.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [2.]\n",
            " [2.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS0sDurDva58"
      },
      "source": [
        "logreg = LogisticRegression(max_iter=99999)\n",
        "\n",
        "# Create an instance of Logistic Regression Classifier and fit the data.\n",
        "logreg.fit(X_train, Y_train.ravel())\n",
        "\n",
        "Y_pred = logreg.predict(X_test)\n",
        "print(Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJRyR6EUCmEx"
      },
      "source": [
        "print(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O4ns5tsBzR6"
      },
      "source": [
        "confusion_table = np.zeros((3,3))\n",
        "\n",
        "for i in range(len(Y_pred)):\n",
        "  confusion_table[int(Y_pred[i]) - 1][int(Y_test[i]) - 1] += 1\n",
        "\n",
        "print(confusion_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNMs2dbD3mWl"
      },
      "source": [
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "h = .02  # step size in the mesh\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(4, 3))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "# Plot also the training points\n",
        "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}